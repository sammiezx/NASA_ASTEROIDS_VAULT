{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from client import hit_nasa_api\n",
    "from adapter import parse_response\n",
    "from connector.cassandra_connector import get_session, create_and_set_keyspace, create_table, save_dataframe_to_cassandra, get_min_max_dates\n",
    "# from log.logger_set import get_logger\n",
    "\n",
    "class CatchStream:\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        with open(os.getenv(\"CONF_PATH\"), 'r') as file:\n",
    "            conf = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "        session = get_session()\n",
    "        create_and_set_keyspace(session, conf['cassandra_keyspace_name'])\n",
    "        create_table(session, conf['cassandra_table_name'])\n",
    "\n",
    "        stream_id = datetime.now().date().strftime('CATCH_STREAM_%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "        self.conf = conf\n",
    "        self.session = session\n",
    "        self.date_offset, _ = get_min_max_dates(session)\n",
    "        # self.logger = get_logger(conf['log_path']+ stream_id + '.log')\n",
    "\n",
    "        logging.basicConfig(filename= conf['log_path']+ stream_id + '.log', level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        self.logger = logging.getLogger(__name__ + f'.instance_{id(self)}')\n",
    "        \n",
    "\n",
    "    def clear_buffer(self):\n",
    "        file_path = self.conf['catchup_buffer_path']\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"File '{file_path}' has been deleted.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{file_path}' not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "    def get_payload(self):\n",
    "        self.logger.info(\"[TARGETING NASA API]\")\n",
    "        conf = self.conf\n",
    "\n",
    "        date_offset = self.date_offset\n",
    "        if(date_offset < datetime.strptime(conf['catch_upto'], \"%Y-%m-%d\")):\n",
    "            raise Exception(\"CAUGHT UP!!, [you can disable the dag now]\")\n",
    "        \n",
    "        end_date = date_offset.strftime('%Y-%m-%d')\n",
    "        start_date = (date_offset - timedelta(days=6)).strftime('%Y-%m-%d')\n",
    "        self.date_offset = date_offset - timedelta(days=6)\n",
    "        print(start_date, end_date)\n",
    "\n",
    "        try:\n",
    "            df = hit_nasa_api(start_date, end_date)\n",
    "            df.to_csv(conf['catchup_buffer_path'], index=False)\n",
    "            self.logger.info(f\"[PAYLOAD INITIALIZED FOR]: {start_date} TO {end_date} batch\")\n",
    "            print(f\"[PAYLOAD INITIALIZED FOR]: {start_date} TO {end_date} batch\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def preprocess_payload(self):\n",
    "        self.logger.info(\"[PROCESSING PAYLOAD]\")\n",
    "        conf = self.conf\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(conf['catchup_buffer_path'])\n",
    "            df = parse_response(df)\n",
    "            # adapter takes care of most of the parsing and all, while more can be added in this task later on\n",
    "            self.clear_buffer()\n",
    "            df.to_csv(conf['catchup_buffer_path'], index=False)\n",
    "            self.logger.info(\"[PAYLOAD PROCESSED FOR]: {start_date} TO {end_date} batch\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def dump_payload(self):\n",
    "        self.logger.info(\"[DUMPING PAYLOAD]\")\n",
    "        conf = self.conf\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(conf['catchup_buffer_path'])\n",
    "            df['neo_reference_id'] = df['neo_reference_id'].astype(str)\n",
    "            df['miss_distance_astronomical'] = df['miss_distance_astronomical'].astype(str)\n",
    "            df['miss_distance_lunar'] = df['miss_distance_lunar'].astype(str)\n",
    "            df['id'] = df['id'].astype(str)\n",
    "\n",
    "            save_dataframe_to_cassandra(self.session, df, conf['cassandra_table_name'])\n",
    "            self.clear_buffer()\n",
    "            # self.logger.info(f\"[PAYLOAD DUMPED FOR]: {start_date} TO {end_date} batch\")\n",
    "            # print(f\"[PAYLOAD DUMPED FOR]: {start_date} TO {end_date} batch\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def stream(self):\n",
    "        while True:\n",
    "            try:\n",
    "                self.get_payload()\n",
    "                self.preprocess_payload()\n",
    "                self.dump_payload()\n",
    "                # time.sleep(100)\n",
    "            except Exception as e:\n",
    "                self.logger.error(\"An error occurred: %s\", str(e), exc_info=True)\n",
    "                raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = CatchStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "CAUGHT UP!!, [you can disable the dag now]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stream\u001b[39m.\u001b[39;49mstream()\n",
      "Cell \u001b[0;32mIn[7], line 111\u001b[0m, in \u001b[0;36mCatchStream.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mAn error occurred: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(e), exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[7], line 105\u001b[0m, in \u001b[0;36mCatchStream.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_payload()\n\u001b[1;32m    106\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_payload()\n\u001b[1;32m    107\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdump_payload()\n",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m, in \u001b[0;36mCatchStream.get_payload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m date_offset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdate_offset\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m(date_offset \u001b[39m<\u001b[39m datetime\u001b[39m.\u001b[39mstrptime(conf[\u001b[39m'\u001b[39m\u001b[39mcatch_upto\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCAUGHT UP!!, [you can disable the dag now]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m end_date \u001b[39m=\u001b[39m date_offset\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m start_date \u001b[39m=\u001b[39m (date_offset \u001b[39m-\u001b[39m timedelta(days\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m))\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: CAUGHT UP!!, [you can disable the dag now]"
     ]
    }
   ],
   "source": [
    "stream.stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
